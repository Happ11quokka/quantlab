# 한국 뉴스 데이터 수집 및 분석 프로젝트

> ⚠️ 이 README 파일은 임시 버전입니다. 추후에 내용을 보완할 예정입니다.

## 📌 프로젝트 목적

한국 뉴스 데이터를 수집하고, 이를 분석하여 시계열 기반의 기업 관련 뉴스 흐름을 정리하는 것을 목표로 합니다.

---

## ⚙️ 사용 방법

1. **데이터 수집**  
   `crawlingnews.py`를 실행하여 Nate 뉴스에서 시간별 데이터를 수집합니다.  
   → 결과는 `nate_news.json` 파일로 저장됩니다.  
   저장 데이터 예시:

   ```json
   {
     "date": "20250101",
     "title": "뉴스 제목",
     "url": "https://...",
     "content": "기사 내용..."
   }
   ```

2. **기사 전송 시간 추출**  
   `nate_news.json` 파일의 `content` 필드에서 기사 전송 시간을 추출하여  
   → `first.json`에 구체적인 시간 정보가 포함된 데이터를 저장합니다.

3. **GPT-4o를 통한 뉴스 분석**  
   `krChat.py`를 실행하여 GPT-4o 모델을 통해 뉴스 분석을 수행합니다.  
   → 결과는 `chattmp2.json`에 저장됩니다.

4. **시간별 정렬 및 기업명 표준화**  
   `secondGpt.py`를 실행하여 `chattmp2.json`을

   - 시간순으로 정렬하고
   - 기업명을 표준화합니다.  
     → 결과는 `second.json`에 저장됩니다.

5. **장전/장중/장후 분류**  
   `secondtmp.py`를 통해 뉴스 데이터를

   - 장전
   - 장중
   - 장후  
     로 나누어  
     → `second_summary.json`에 저장합니다.

6. **최종 정리 및 결과 반환**  
   마지막으로,
   - 기업명을 한국거래소(KRX) 기준으로 수정하고
   - 최종 분석 결과를 정리하여 코드와 함께  
     → `final.json` 파일로 저장합니다.

---

## 📁 주요 파일 설명

| 파일명            | 설명                              |
| ----------------- | --------------------------------- |
| `crawlingnews.py` | Nate 뉴스 데이터 크롤링           |
| `krChat.py`       | GPT-4o를 활용한 기사 내용 분석    |
| `secondGpt.py`    | 시간 정렬 및 기업명 표준화        |
| `secondtmp.py`    | 뉴스 시간대 분류 (장전/장중/장후) |
| `*.json`          | 각 단계별로 저장되는 데이터 파일  |

---

## 📝 TODO

- README 상세 내용 보완
- 논문 구현
- 오류 처리 및 예외 케이스 보완
